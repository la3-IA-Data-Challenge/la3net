{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.9 64-bit ('data_challenge': conda)",
   "metadata": {
    "interpreter": {
     "hash": "a76cc6609b19670ed5a5beefd81c358fe89c0b57f12198349bbcd36312527f13"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "\n",
    "from core.utils.extractors import Encoder\n",
    "from core.utils.evaluator import Evaluator\n",
    "from core.clustering import get_closest_cluster\n",
    "from core.duplicate_search import search_duplicates_mn, search_duplicates_hash, search_duplicates_orb, performance\n",
    "\n",
    "from sklearn_extra.cluster import KMedoids\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "import pickle\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import matplotlib.cm as cm\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For reproducibility\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Nombres d'images: 240\n"
     ]
    }
   ],
   "source": [
    "IMAGESDIR = \"./data/near_duplicates/\"\n",
    "print(\"Nombres d'images: {0}\".format(len(os.listdir(IMAGESDIR))))\n",
    "nb_images = len(os.listdir(IMAGESDIR))"
   ]
  },
  {
   "source": [
    "## Load computed clusters"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "centroids = pickle.load(open(\"./clusters/centroids.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = pickle.load(open(\"./clusters/labels.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_features = pickle.load(open(\"./features/features_mn.pkl\", \"rb\"))"
   ]
  },
  {
   "source": [
    "## Find closest cluster\n",
    "\n",
    "#### Get closest cluster"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2020-12-06 14:44:53,277: INFO Initialized: MobileNet pretrained on ImageNet dataset sliced at last conv layer and added GlobalAveragePooling\n",
      "The closest cluster is 0.\n",
      "Wall time: 6.63 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "input_path = IMAGESDIR + '00004.jpg'\n",
    "clust = get_closest_cluster(input_path, centroids)\n",
    "print(f\"The closest cluster is {clust}.\")"
   ]
  },
  {
   "source": [
    "## Find duplicates or near images\n",
    "\n",
    "#### Get images' features in cluster"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes = np.where(labels == clust)[0]"
   ]
  },
  {
   "source": [
    "#### Search for duplicates using MobileNet"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2020-12-06 14:44:55,731: INFO Initialized: MobileNet pretrained on ImageNet dataset sliced at last conv layer and added GlobalAveragePooling\n",
      "MobileNet\n",
      "----------\n",
      "Found images at [3] indexes as duplicates and the next closest image at 10.\n",
      "Wall time: 2.22 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "duplicates, closest = search_duplicates_mn(input_path, indexes, imgs_features)\n",
    "print(\"MobileNet\")\n",
    "print(\"-\"*10)\n",
    "print(f\"Found images at {duplicates} indexes as duplicates and the next closest image at {closest}.\")"
   ]
  },
  {
   "source": [
    "#### Search for duplicates using hashing methods"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = [os.path.join(IMAGESDIR, file) for file in os.listdir(IMAGESDIR)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "PHash\n----------\nFound images at [3] indexes as duplicates and the next closest image at 61.\nWall time: 1.01 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "duplicates, closest = search_duplicates_hash(input_path, indexes, filenames, mode=\"phash\")\n",
    "print(\"PHash\")\n",
    "print(\"-\"*10)\n",
    "print(f\"Found images at {duplicates} indexes as duplicates and the next closest image at {closest}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "AHash\n----------\nFound images at [3, 95] indexes as duplicates and the next closest image at 72.\nWall time: 914 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "duplicates, closest = search_duplicates_hash(input_path, indexes, filenames, mode=\"ahash\")\n",
    "print(\"AHash\")\n",
    "print(\"-\"*10)\n",
    "print(f\"Found images at {duplicates} indexes as duplicates and the next closest image at {closest}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "DHash\n----------\nFound images at [3] indexes as duplicates and the next closest image at 170.\nWall time: 917 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "duplicates, closest = search_duplicates_hash(input_path, indexes, filenames, mode=\"dhash\")\n",
    "print(\"DHash\")\n",
    "print(\"-\"*10)\n",
    "print(f\"Found images at {duplicates} indexes as duplicates and the next closest image at {closest}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "WHash\n----------\nFound images at [3, 15, 64, 72, 75, 80, 95, 98, 106] indexes as duplicates and the next closest image at 58.\nWall time: 1.23 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "duplicates, closest = search_duplicates_hash(input_path, indexes, filenames, mode=\"whash\")\n",
    "print(\"WHash\")\n",
    "print(\"-\"*10)\n",
    "print(f\"Found images at {duplicates} indexes as duplicates and the next closest image at {closest}.\")"
   ]
  },
  {
   "source": [
    "#### Search for duplicates using ORB descriptor"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ORB\n----------\nFound images at [3] indexes as duplicates and the next closest image at 80.\nWall time: 1.91 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "duplicates, closest = search_duplicates_orb(input_path, indexes, filenames)\n",
    "print(\"ORB\")\n",
    "print(\"-\"*10)\n",
    "print(f\"Found images at {duplicates} indexes as duplicates and the next closest image at {closest}.\")"
   ]
  },
  {
   "source": [
    "#### Select image to test"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = [np.random.choice(np.where(labels == clust)[0], 1)[0] for clust in range(5)]\n",
    "indexes = [list(np.where(labels == clust)[0]) for clust in range(5) ]\n",
    "evaluator = Evaluator(\"./data/out.csv\")\n",
    "\n",
    "perf = pd.DataFrame(columns=[\"model\", \"precision\", \"recall\", \"duration\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2020-12-06 14:45:04,224: INFO Initialized: MobileNet pretrained on ImageNet dataset sliced at last conv layer and added GlobalAveragePooling\n",
      "Cluster 0 - image n°3 - [3] as duplicates - Precision: 1.0 - Recall: 1.0\n",
      "2020-12-06 14:45:06,437: INFO Initialized: MobileNet pretrained on ImageNet dataset sliced at last conv layer and added GlobalAveragePooling\n",
      "Cluster 1 - image n°37 - [6, 37, 46, 54] as duplicates - Precision: 0.25 - Recall: 1.0\n",
      "2020-12-06 14:45:12,179: INFO Initialized: MobileNet pretrained on ImageNet dataset sliced at last conv layer and added GlobalAveragePooling\n",
      "Cluster 2 - image n°29 - [29] as duplicates - Precision: 1.0 - Recall: 1.0\n",
      "2020-12-06 14:45:14,517: INFO Initialized: MobileNet pretrained on ImageNet dataset sliced at last conv layer and added GlobalAveragePooling\n",
      "Cluster 3 - image n°25 - [25] as duplicates - Precision: 1.0 - Recall: 1.0\n",
      "2020-12-06 14:45:17,142: INFO Initialized: MobileNet pretrained on ImageNet dataset sliced at last conv layer and added GlobalAveragePooling\n",
      "Cluster 4 - image n°132 - [132] as duplicates - Precision: 1.0 - Recall: 0.3333333333333333\n",
      "MobileNet - Precision: 0.85 - Recall: 0.8666666666666666 - F1 Score: 0.8582524271844659\n",
      "Wall time: 15.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "start = time.time()\n",
    "precision, recall, f1_score = performance(filenames, \"mobilenet\", ids, indexes, evaluator, imgs_features)\n",
    "row = pd.DataFrame({\n",
    "    \"model\": [\"mobilenet\"],\n",
    "    \"precision\": [precision],\n",
    "    \"recall\": [recall],\n",
    "    \"duration\": [time.time() - start]\n",
    "})\n",
    "perf = perf.append(row, ignore_index=True)\n",
    "print(f\"MobileNet - Precision: {precision} - Recall: {recall} - F1 Score: {f1_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Cluster 0 - image n°3 - [3] as duplicates - Precision: 1.0 - Recall: 1.0\n",
      "Cluster 1 - image n°37 - [6, 37, 46, 54] as duplicates - Precision: 0.25 - Recall: 1.0\n",
      "Cluster 2 - image n°29 - [29] as duplicates - Precision: 1.0 - Recall: 1.0\n",
      "Cluster 3 - image n°25 - [25] as duplicates - Precision: 1.0 - Recall: 1.0\n",
      "Cluster 4 - image n°132 - [132] as duplicates - Precision: 1.0 - Recall: 0.3333333333333333\n",
      "PHash - Precision: 0.85 - Recall: 0.8666666666666666 - F1 Score: 0.8582524271844659\n",
      "Wall time: 1min 11s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "start = time.time()\n",
    "precision, recall, f1_score = performance(filenames, \"phash\", ids, indexes, evaluator)\n",
    "row = pd.DataFrame({\n",
    "    \"model\": [\"phash\"],\n",
    "    \"precision\": [precision],\n",
    "    \"recall\": [recall],\n",
    "    \"duration\": [time.time() - start]\n",
    "})\n",
    "perf = perf.append(row, ignore_index=True)\n",
    "print(f\"PHash - Precision: {precision} - Recall: {recall} - F1 Score: {f1_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Cluster 0 - image n°3 - [3, 95] as duplicates - Precision: 0.5 - Recall: 1.0\n",
      "Cluster 1 - image n°37 - [6, 37, 46, 54] as duplicates - Precision: 0.25 - Recall: 1.0\n",
      "Cluster 2 - image n°29 - [29, 30, 85] as duplicates - Precision: 0.3333333333333333 - Recall: 1.0\n",
      "Cluster 3 - image n°25 - [25] as duplicates - Precision: 1.0 - Recall: 1.0\n",
      "Cluster 4 - image n°132 - [130, 132] as duplicates - Precision: 1.0 - Recall: 0.6666666666666666\n",
      "AHash - Precision: 0.6166666666666666 - Recall: 0.9333333333333333 - F1 Score: 0.7426523297491039\n",
      "Wall time: 1min 7s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "start = time.time()\n",
    "precision, recall, f1_score = performance(filenames, \"ahash\", ids, indexes, evaluator)\n",
    "row = pd.DataFrame({\n",
    "    \"model\": [\"ahash\"],\n",
    "    \"precision\": [precision],\n",
    "    \"recall\": [recall],\n",
    "    \"duration\": [time.time() - start]\n",
    "})\n",
    "perf = perf.append(row, ignore_index=True)\n",
    "print(f\"AHash - Precision: {precision} - Recall: {recall} - F1 Score: {f1_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Cluster 0 - image n°3 - [3] as duplicates - Precision: 1.0 - Recall: 1.0\n",
      "Cluster 1 - image n°37 - [6, 37, 46, 54] as duplicates - Precision: 0.25 - Recall: 1.0\n",
      "Cluster 2 - image n°29 - [29] as duplicates - Precision: 1.0 - Recall: 1.0\n",
      "Cluster 3 - image n°25 - [25] as duplicates - Precision: 1.0 - Recall: 1.0\n",
      "Cluster 4 - image n°132 - [132] as duplicates - Precision: 1.0 - Recall: 0.3333333333333333\n",
      "DHash - Precision: 0.85 - Recall: 0.8666666666666666 - F1 Score: 0.8582524271844659\n",
      "Wall time: 1min 8s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "start = time.time()\n",
    "precision, recall, f1_score = performance(filenames, \"dhash\", ids, indexes, evaluator)\n",
    "row = pd.DataFrame({\n",
    "    \"model\": [\"dhash\"],\n",
    "    \"precision\": [precision],\n",
    "    \"recall\": [recall],\n",
    "    \"duration\": [time.time() - start]\n",
    "})\n",
    "perf = perf.append(row, ignore_index=True)\n",
    "print(f\"DHash - Precision: {precision} - Recall: {recall} - F1 Score: {f1_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Cluster 0 - image n°3 - [3, 15, 64, 72, 75, 80, 95, 98, 106] as duplicates - Precision: 0.1111111111111111 - Recall: 1.0\n",
      "Cluster 1 - image n°37 - [6, 37, 46, 54] as duplicates - Precision: 0.25 - Recall: 1.0\n",
      "Cluster 2 - image n°29 - [29, 151] as duplicates - Precision: 0.5 - Recall: 1.0\n",
      "Cluster 3 - image n°25 - [25] as duplicates - Precision: 1.0 - Recall: 1.0\n",
      "Cluster 4 - image n°132 - [132] as duplicates - Precision: 1.0 - Recall: 0.3333333333333333\n",
      "WHash - Precision: 0.5722222222222222 - Recall: 0.8666666666666666 - F1 Score: 0.6893178893178893\n",
      "Wall time: 1min 16s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "start = time.time()\n",
    "precision, recall, f1_score = performance(filenames, \"whash\", ids, indexes, evaluator)\n",
    "row = pd.DataFrame({\n",
    "    \"model\": [\"whash\"],\n",
    "    \"precision\": [precision],\n",
    "    \"recall\": [recall],\n",
    "    \"duration\": [time.time() - start]\n",
    "})\n",
    "perf = perf.append(row, ignore_index=True)\n",
    "print(f\"WHash - Precision: {precision} - Recall: {recall} - F1 Score: {f1_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Cluster 0 - image n°3 - [3] as duplicates - Precision: 1.0 - Recall: 1.0\n",
      "Cluster 1 - image n°37 - [6, 37, 46, 54] as duplicates - Precision: 0.25 - Recall: 1.0\n",
      "Cluster 2 - image n°29 - [29, 59] as duplicates - Precision: 0.5 - Recall: 1.0\n",
      "Cluster 3 - image n°25 - [25] as duplicates - Precision: 1.0 - Recall: 1.0\n",
      "Cluster 4 - image n°132 - [132] as duplicates - Precision: 1.0 - Recall: 0.3333333333333333\n",
      "ORB - Precision: 0.75 - Recall: 0.8666666666666666 - F1 Score: 0.8041237113402061\n",
      "Wall time: 1min 19s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "start = time.time()\n",
    "precision, recall, f1_score = performance(filenames, \"orb\", ids, indexes, evaluator)\n",
    "row = pd.DataFrame({\n",
    "    \"model\": [\"orb\"],\n",
    "    \"precision\": [precision],\n",
    "    \"recall\": [recall],\n",
    "    \"duration\": [time.time() - start]\n",
    "})\n",
    "perf = perf.append(row, ignore_index=True)\n",
    "print(f\"ORB - Precision: {precision} - Recall: {recall} - F1 Score: {f1_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "       model  precision    recall duration\n",
       "0  mobilenet   0.850000  0.866667      NaN\n",
       "1      phash   0.850000  0.866667  71.1675\n",
       "2      ahash   0.616667  0.933333  67.7735\n",
       "3      dhash   0.850000  0.866667   68.305\n",
       "4      whash   0.572222  0.866667   76.326\n",
       "5        orb   0.750000  0.866667   79.311"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>model</th>\n      <th>precision</th>\n      <th>recall</th>\n      <th>duration</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>mobilenet</td>\n      <td>0.850000</td>\n      <td>0.866667</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>phash</td>\n      <td>0.850000</td>\n      <td>0.866667</td>\n      <td>71.1675</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>ahash</td>\n      <td>0.616667</td>\n      <td>0.933333</td>\n      <td>67.7735</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>dhash</td>\n      <td>0.850000</td>\n      <td>0.866667</td>\n      <td>68.305</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>whash</td>\n      <td>0.572222</td>\n      <td>0.866667</td>\n      <td>76.326</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>orb</td>\n      <td>0.750000</td>\n      <td>0.866667</td>\n      <td>79.311</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "source": [
    "perf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'model,precision,recall,duration\\r\\nmobilenet,0.85,0.8666666666666666,\\r\\nphash,0.85,0.8666666666666666,71.16751861572266\\r\\nahash,0.6166666666666666,0.9333333333333333,67.77351570129395\\r\\ndhash,0.85,0.8666666666666666,68.30499982833862\\r\\nwhash,0.5722222222222222,0.8666666666666666,76.32601857185364\\r\\norb,0.75,0.8666666666666666,79.31102466583252\\r\\n'"
      ]
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "source": [
    "perf.to_csv(index=False)"
   ]
  }
 ]
}